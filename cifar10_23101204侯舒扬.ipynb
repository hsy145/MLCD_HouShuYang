{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习课程设计任务\n",
    "1. 使用机器学习以及人工智能应用课程上学习到的机器学习相关理论与算法，使用CIFAR-10数据训练10分类的机器学习模型。\n",
    "2. 将学习到的模型部署为一个web-demo：在网页中上传新的图像，显示图像，使用学习到的模型进行预测，输出预测的分类类别。\n",
    "\n",
    "## 机器学习课程设计要求\n",
    "1. 熟悉并掌握机器学习全过程：数据准备、模型训练和模型选择、模型测试、模型部署\n",
    "2. 熟悉sklearn、pytorch机器学习库的使用，掌握使用它们构建模型、解决实际问题的步骤和方法。\n",
    "3. 要求尝试使用三类模型(算法)进行机器学习，其中至少一种使用sklearn库中的算法，每类模型选择最优参数。然后在三类模型中选择最优模型作为最终模型，最终模型在测试集上的准确率作为评分的依据。\n",
    "4. 要求使用学习的最优模型，基于streamlit将模型部署为一个web-demo，显示新上传的图像并显示分类结果。\n",
    "\n",
    "说明（如果不做模型部署则对应相应的低档）：\n",
    "+ 三个模型全部使用sklearn构建 （仅使用传统机器学习算法-对应D档、C档）\n",
    "+ 分别使用sklearn和pytorch构建模型（结合使用深度学习算法，对应B档、A档）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、数据读取及显示\n",
    "CIFAR-10是一个包含60000张32x32彩色图片的数据集，其中包括10个类别的图片，每个类别有6000张图片。这个数据集通常用于图像分类任务的训练和测试。\n",
    "\n",
    "CIFAR-10数据集的10个类别分别是：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。\n",
    "\n",
    "关于CIFAR-10数据集的更多信息可以在以下链接找到： https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:29:24.847230Z",
     "start_time": "2026-01-09T12:29:17.546822Z"
    }
   },
   "outputs": [],
   "source": [
    "# 标准库\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "# 数据科学与绘图\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch 核心\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 计算机视觉\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:29:24.909078Z",
     "start_time": "2026-01-09T12:29:24.894074Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取CIFAR-10数据集的函数\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:29:25.161257Z",
     "start_time": "2026-01-09T12:29:24.912078Z"
    }
   },
   "outputs": [],
   "source": [
    "##读取CIFAR-10数据集\n",
    "data_batch_1 = unpickle('datasets/data_batch_1')\n",
    "data_batch_2 = unpickle('datasets/data_batch_2')\n",
    "data_batch_3 = unpickle('datasets/data_batch_3')\n",
    "data_batch_4 = unpickle('datasets/data_batch_4')\n",
    "data_batch_5 = unpickle('datasets/data_batch_5')\n",
    "test_batch = unpickle('datasets/test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:29:25.223772Z",
     "start_time": "2026-01-09T12:29:25.178265Z"
    }
   },
   "outputs": [],
   "source": [
    "##整合成所需要的数据\n",
    "x_train = np.concatenate((data_batch_1[b'data'], data_batch_2[b'data'], data_batch_3[b'data'], data_batch_4[b'data'], data_batch_5[b'data']), axis=0)\n",
    "y_train = np.concatenate((data_batch_1[b'labels'], data_batch_2[b'labels'], data_batch_3[b'labels'], data_batch_4[b'labels'], data_batch_5[b'labels']), axis=0)\n",
    "x_test = test_batch[b'data']\n",
    "y_test = np.array(test_batch[b'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意图像数据的组织：**\n",
    "+ NCHW 中，C 排列在外层，每个通道内像素紧挨在一起，即 ‘RRRRRRGGGGGGBBBBBB’ 这种形式。 \n",
    "+ NHWC 格式，C 排列在最内层，多个通道对应空间位置的像素紧挨在一起，即 ‘RGBRGBRGBRGBRGBRGB’\n",
    "\n",
    "Nvidia cudnn以及pytorch使用NCHW的形式，tensorflow默认NHWC的形式（可以设为 NCHW的形式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:29:27.829101Z",
     "start_time": "2026-01-09T12:29:27.699124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072,)\n",
      "[[ 59  43  50 ... 140  84  72]\n",
      " [154 126 105 ... 139 142 144]\n",
      " [255 253 253 ...  83  83  84]\n",
      " ...\n",
      " [114 117 120 ... 182 192 187]\n",
      " [ 76  73  69 ... 127 127 130]\n",
      " [ 65  70  76 ...  45  30  21]]\n",
      "[6 9 9 4 1 1 2 7 8 3 4 7 7 2 9 9 9 3 2 6 4 3 6 6 2 6 3 5 4 0 0 9 1 3 4 0 3\n",
      " 7 3 3 5 2 2 7 1 1 1 2 2 0 9 5 7 9 2 2 5 2 4 3 1 1 8 2]\n"
     ]
    }
   ],
   "source": [
    "img=x_train[7].reshape(3,32,32)\n",
    "\n",
    "plt.imshow(img.transpose((1,2,0)))\n",
    "plt.show()\n",
    "print(x_train[7].shape)\n",
    "print(x_train[0:64])   \n",
    "print(y_train[0:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习可以使用的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:29:30.721267Z",
     "start_time": "2026-01-09T12:29:29.840176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: (40000, 3072) (40000,)\n",
      "验证集大小: (10000, 3072) (10000,)\n",
      "测试集大小: (10000, 3072) (10000,)\n",
      "\n",
      "sklearn数据格式 - 训练集: (40000, 3072)\n",
      "sklearn数据格式 - 验证集: (10000, 3072)\n",
      "sklearn数据格式 - 测试集: (10000, 3072)\n",
      "\n",
      "PyTorch数据格式 - 训练集: torch.Size([40000, 3072]) 标签: torch.Size([40000])\n",
      "PyTorch数据格式 - 验证集: torch.Size([10000, 3072]) 标签: torch.Size([10000])\n",
      "PyTorch数据格式 - 测试集: torch.Size([10000, 3072]) 标签: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# 1. 数据归一化处理（将像素值从[0,255]归一化到[0,1]）\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# 2. 将训练集分成训练集和验证集\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=23101204) ##后面用到的函数中如有\"random_state\"参数同此处理\n",
    "print('训练集大小:', x_train.shape, y_train.shape)\n",
    "print('验证集大小:', x_val.shape, y_val.shape)\n",
    "print('测试集大小:', x_test.shape, y_test.shape)\n",
    "\n",
    "# 3. 为sklearn模型准备数据（展平为二维数组）\n",
    "x_train_sklearn = x_train.reshape(x_train.shape[0], -1)  # (40000, 3072)\n",
    "x_val_sklearn = x_val.reshape(x_val.shape[0], -1)        # (10000, 3072)\n",
    "x_test_sklearn = x_test.reshape(x_test.shape[0], -1)      # (10000, 3072)\n",
    "\n",
    "print('\\nsklearn数据格式 - 训练集:', x_train_sklearn.shape)\n",
    "print('sklearn数据格式 - 验证集:', x_val_sklearn.shape)\n",
    "print('sklearn数据格式 - 测试集:', x_test_sklearn.shape)\n",
    "\n",
    "# 4. 为PyTorch模型准备数据（保持为四维张量并转换）\n",
    "x_train_pytorch = torch.from_numpy(x_train).float()  # 保持NHWC格式 (40000, 32, 32, 3)\n",
    "x_val_pytorch = torch.from_numpy(x_val).float()\n",
    "x_test_pytorch = torch.from_numpy(x_test).float()\n",
    "\n",
    "y_train_pytorch = torch.from_numpy(y_train).long()\n",
    "y_val_pytorch = torch.from_numpy(y_val).long()\n",
    "y_test_pytorch = torch.from_numpy(y_test).long()\n",
    "\n",
    "print('\\nPyTorch数据格式 - 训练集:', x_train_pytorch.shape, '标签:', y_train_pytorch.shape)\n",
    "print('PyTorch数据格式 - 验证集:', x_val_pytorch.shape, '标签:', y_val_pytorch.shape)\n",
    "print('PyTorch数据格式 - 测试集:', x_test_pytorch.shape, '标签:', y_test_pytorch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 具体类别信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:29:37.063511Z",
     "start_time": "2026-01-09T12:29:37.049511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类类别数: 10\n",
      "0 airplane\n",
      "1 automobile\n",
      "2 bird\n",
      "3 cat\n",
      "4 deer\n",
      "5 dog\n",
      "6 frog\n",
      "7 horse\n",
      "8 ship\n",
      "9 truck\n"
     ]
    }
   ],
   "source": [
    "batches_meta=unpickle('datasets/batches.meta')\n",
    "\n",
    "label_names= batches_meta[b'label_names']\n",
    "label_names= [name.decode('utf-8') for name in label_names]\n",
    "label_names=np.array(label_names)\n",
    "print('分类类别数:', label_names.shape[0])\n",
    "for index in range(0, label_names.shape[0]):\n",
    "    print(index, label_names[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、模型训练与模型选择\n",
    "每个人自由选择传统机器学习算法（ML课程中讲到的如）或者人工神经网络（深度学习）的模型,可以使用skearn和pytorch库。\n",
    "+ K近邻、logistic回归、SVM、决策树、随机森林、梯度boosting等方法 \n",
    "+ MLP，CNN，Resnet等\n",
    "\n",
    "1.选择不同的学习算法或模型，或者结合多种算法，完成模型的训练 \n",
    "2.使用验证集选择不同的模型或者不同的参数\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型1 XGBoost的数据准备，模型训练与参数选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T01:12:41.020207Z",
     "start_time": "2026-01-09T01:12:24.339389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练模型 1: XGBoost\n",
      "正在使用验证集进行参数选择...\n",
      "\n",
      " n_estimators=100, learning_rate=0.1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x000002C5D78C6B40>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\15075\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 585, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x000002C5D78C6B40>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\15075\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 585, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x000002C5D78C6B40>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\15075\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py\", line 585, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[09:12:40] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\quantile_dmatrix.cc:174: Check failed: accumulated_rows == info.num_row_ (160000 vs. 40000) : ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 37\u001b[0m\n\u001b[0;32m     25\u001b[0m model_xgb \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\n\u001b[0;32m     26\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mn_trees,\n\u001b[0;32m     27\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m   \u001b[38;5;66;03m# 防止过拟合，如果10轮没提升就停止\u001b[39;00m\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m model_xgb\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     38\u001b[0m     x_train_sklearn, y_train,\n\u001b[0;32m     39\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[(x_val_sklearn, y_val)],\n\u001b[0;32m     40\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# 验证\u001b[39;00m\n\u001b[0;32m     44\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m model_xgb\u001b[38;5;241m.\u001b[39mpredict(x_val_sklearn)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py:1664\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[0;32m   1661\u001b[0m model, metric, params, feature_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1662\u001b[0m     xgb_model, params, feature_weights\n\u001b[0;32m   1663\u001b[0m )\n\u001b[1;32m-> 1664\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1665\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1666\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1667\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   1668\u001b[0m     group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1669\u001b[0m     qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1670\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1671\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1672\u001b[0m     feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m   1673\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39meval_set,\n\u001b[0;32m   1674\u001b[0m     sample_weight_eval_set\u001b[38;5;241m=\u001b[39msample_weight_eval_set,\n\u001b[0;32m   1675\u001b[0m     base_margin_eval_set\u001b[38;5;241m=\u001b[39mbase_margin_eval_set,\n\u001b[0;32m   1676\u001b[0m     eval_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1677\u001b[0m     eval_qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1678\u001b[0m     create_dmatrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dmatrix,\n\u001b[0;32m   1679\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[0;32m   1680\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1681\u001b[0m )\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1684\u001b[0m     params,\n\u001b[0;32m   1685\u001b[0m     train_dmatrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1694\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1695\u001b[0m )\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py:628\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    609\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    625\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    626\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m create_dmatrix(\n\u001b[0;32m    629\u001b[0m         data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    630\u001b[0m         label\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    631\u001b[0m         group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m    632\u001b[0m         qid\u001b[38;5;241m=\u001b[39mqid,\n\u001b[0;32m    633\u001b[0m         weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    634\u001b[0m         base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m    635\u001b[0m         feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m    636\u001b[0m         missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    637\u001b[0m         enable_categorical\u001b[38;5;241m=\u001b[39menable_categorical,\n\u001b[0;32m    638\u001b[0m         feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[0;32m    639\u001b[0m         ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[0;32m    642\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py:1137\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[0;32m   1138\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, ref\u001b[38;5;241m=\u001b[39mref, nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[0;32m   1139\u001b[0m         )\n\u001b[0;32m   1140\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:1614\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, max_quantile_batches, data_split_mode)\u001b[0m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1595\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1596\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1607\u001b[0m         )\n\u001b[0;32m   1608\u001b[0m     ):\n\u001b[0;32m   1609\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1610\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1611\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1612\u001b[0m         )\n\u001b[1;32m-> 1614\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(\n\u001b[0;32m   1615\u001b[0m     data,\n\u001b[0;32m   1616\u001b[0m     ref\u001b[38;5;241m=\u001b[39mref,\n\u001b[0;32m   1617\u001b[0m     label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[0;32m   1618\u001b[0m     weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[0;32m   1619\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1620\u001b[0m     group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m   1621\u001b[0m     qid\u001b[38;5;241m=\u001b[39mqid,\n\u001b[0;32m   1622\u001b[0m     label_lower_bound\u001b[38;5;241m=\u001b[39mlabel_lower_bound,\n\u001b[0;32m   1623\u001b[0m     label_upper_bound\u001b[38;5;241m=\u001b[39mlabel_upper_bound,\n\u001b[0;32m   1624\u001b[0m     feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m   1625\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m   1626\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[0;32m   1627\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39menable_categorical,\n\u001b[0;32m   1628\u001b[0m     max_quantile_blocks\u001b[38;5;241m=\u001b[39mmax_quantile_batches,\n\u001b[0;32m   1629\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:1680\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, max_quantile_blocks, **meta)\u001b[0m\n\u001b[0;32m   1678\u001b[0m it\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m-> 1680\u001b[0m _check_call(ret)\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:310\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [09:12:40] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\quantile_dmatrix.cc:174: Check failed: accumulated_rows == info.num_row_ (160000 vs. 40000) : "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "print(\"开始训练模型 1: XGBoost\")\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': 100, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 200, 'learning_rate': 0.1},\n",
    "]\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "best_model_xgb = None\n",
    "\n",
    "for params in param_grid:\n",
    "    n_trees = params['n_estimators']\n",
    "    lr = params['learning_rate']\n",
    "\n",
    "    print(f\"\\n n_estimators={n_trees}, learning_rate={lr} ...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 初始化模型\n",
    "    model_xgb = xgb.XGBClassifier(\n",
    "        n_estimators=n_trees,\n",
    "        learning_rate=lr,\n",
    "        objective='multi:softmax', # 多分类问题\n",
    "        num_class=10,              # 10 类\n",
    "        tree_method='hist',        # 使用直方图算法\n",
    "        device='cuda',             # 使用 GPU\n",
    "        random_state=23101204,\n",
    "        early_stopping_rounds=10   # 防止过拟合\n",
    "    )\n",
    "\n",
    "    # 训练\n",
    "    model_xgb.fit(\n",
    "        x_train_sklearn, y_train,\n",
    "        eval_set=[(x_val_sklearn, y_val)],\n",
    "        verbose=10\n",
    "    )\n",
    "\n",
    "    # 验证\n",
    "    val_pred = model_xgb.predict(x_val_sklearn)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"耗时: {end_time - start_time:.2f} 秒\")\n",
    "    print(f\"验证集准确率: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_params = params\n",
    "        best_model_xgb = model_xgb\n",
    "\n",
    "print(\"\\n---------------------------------------------------------\")\n",
    "print(f\"最佳参数: {best_params}\")\n",
    "print(f\"最佳验证集准确率: {best_acc:.4f}\")\n",
    "\n",
    "with open('checkpoints/best_xgboost_cifar10.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model_xgb, f)\n",
    "print(\"XGBoost模型已保存至 checkpoints/best_xgboost_cifar10.pkl\")\n",
    "\n",
    "print(\"\\n最佳模型详细报告:\")\n",
    "print(classification_report(y_val, best_model_xgb.predict(x_val_sklearn), target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN的数据准备，模型训练与CNN参数选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T12:26:05.385171Z",
     "start_time": "2026-01-08T12:24:33.310062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前设备: cuda\n",
      "\n",
      "开始训练 (共 50 轮)...\n",
      "--------------------------------------------------\n",
      "Epoch [10/50] | 训练Acc: 0.8161 | 验证Acc: 0.7577\n",
      "Epoch [20/50] | 训练Acc: 0.9143 | 验证Acc: 0.7878\n",
      "Epoch [30/50] | 训练Acc: 0.9506 | 验证Acc: 0.7521\n",
      "Epoch [40/50] | 训练Acc: 0.9654 | 验证Acc: 0.7828\n",
      "Epoch [50/50] | 训练Acc: 0.9742 | 验证Acc: 0.7816\n",
      "--------------------------------------------------\n",
      "训练结束。最佳验证集准确率: 0.7918\n",
      "CNN模型已保存至 checkpoints/best_cnn_cifar10.pth\n"
     ]
    }
   ],
   "source": [
    "# 1. 数据准备 (NCHW 格式)\n",
    "from models.CNN import CIFAR10_CNN\n",
    "\n",
    "X_train_cnn = x_train_pytorch.view(-1, 3, 32, 32)\n",
    "X_val_cnn = x_val_pytorch.view(-1, 3, 32, 32)\n",
    "\n",
    "# 创建 DataLoader\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train_cnn, y_train_pytorch)\n",
    "val_dataset = TensorDataset(X_val_cnn, y_val_pytorch)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"当前设备: {device}\")\n",
    "\n",
    "# 2. 训练配置\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model_cnn = CIFAR10_CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_cnn = None\n",
    "\n",
    "print(f\"\\n开始训练 模型2: CNN (共 {epochs} 轮)...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # --- 训练阶段 ---\n",
    "    model_cnn.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算训练集准确率\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # --- 验证阶段 ---\n",
    "    model_cnn.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_cnn(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_cnn = model_cnn\n",
    "\n",
    "    # 每10轮输出一次\n",
    "    if (epoch + 1) % 10 == 0 or (epoch + 1) == epochs:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | 训练Acc: {train_acc:.4f} | 验证Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"训练结束。最佳验证集准确率: {best_acc:.4f}\")\n",
    "\n",
    "torch.save(best_model_cnn.state_dict(), 'checkpoints/best_cnn_cifar10.pth')\n",
    "print(\"CNN模型已保存至 checkpoints/best_cnn_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型3 ResNet18的数据准备，模型训练与参数选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T12:38:00.612233Z",
     "start_time": "2026-01-08T12:37:51.495219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型3: ResNet-18 准备就绪 (设备: cuda)\n",
      "\n",
      "开始训练 模型3: ResNet-18 (共 30 轮)...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 118\u001b[0m\n\u001b[0;32m    116\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    117\u001b[0m     train_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 118\u001b[0m     train_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    120\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m train_correct \u001b[38;5;241m/\u001b[39m train_total\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# --- 验证阶段 ---\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. 数据准备 (NCHW 格式)\n",
    "from models.ResNet import ResNet18\n",
    "\n",
    "X_train_res = x_train_pytorch.view(-1, 3, 32, 32)\n",
    "X_val_res = x_val_pytorch.view(-1, 3, 32, 32)\n",
    "\n",
    "# 创建 DataLoader\n",
    "batch_size = 256\n",
    "train_dataset = TensorDataset(X_train_res, y_train_pytorch)\n",
    "val_dataset = TensorDataset(X_val_res, y_val_pytorch)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"模型3: ResNet-18 准备就绪 (设备: {device})\")\n",
    "\n",
    "# 2. 训练配置\n",
    "learning_rate = 0.001\n",
    "epochs = 30\n",
    "\n",
    "print(f\"\\n开始训练 模型3: ResNet-18 (共 {epochs} 轮)...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "model_res = ResNet18().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_res.parameters(), lr=learning_rate)\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_res = None\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # --- 训练阶段 ---\n",
    "    model_res.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_res(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # --- 验证阶段 ---\n",
    "    model_res.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_res(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_res = model_res\n",
    "\n",
    "    # 每5轮输出一次\n",
    "    if (epoch + 1) % 5 == 0 or (epoch + 1) == epochs:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | 训练Acc: {train_acc:.4f} | 验证Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"训练结束。ResNet-18 最佳验证集准确率: {best_acc:.4f}\")\n",
    "\n",
    "torch.save(best_model_res.state_dict(), 'checkpoints/best_resnet18_cifar10.pth')\n",
    "print(\"ResNet-18模型已保存至 checkpoints/best_resnet18_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## air_bench94模型4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T02:42:01.787135Z",
     "start_time": "2026-01-09T02:40:27.618493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型4: CifarNet 准备就绪 (带数据增强+TTA)\n",
      "开始训练 (共 10 轮)...\n",
      "--------------------------------------------------\n",
      "  -> 保存最佳模型\n",
      "Epoch [1/10] | 训练Acc: 0.6081 | 验证Acc: 0.4626\n",
      "  -> 保存最佳模型\n",
      "Epoch [2/10] | 训练Acc: 0.7780 | 验证Acc: 0.6984\n",
      "  -> 保存最佳模型\n",
      "Epoch [3/10] | 训练Acc: 0.8094 | 验证Acc: 0.8026\n",
      "Epoch [4/10] | 训练Acc: 0.8386 | 验证Acc: 0.7899\n",
      "  -> 保存最佳模型\n",
      "Epoch [5/10] | 训练Acc: 0.8622 | 验证Acc: 0.8153\n",
      "  -> 保存最佳模型\n",
      "Epoch [6/10] | 训练Acc: 0.8847 | 验证Acc: 0.8273\n",
      "  -> 保存最佳模型\n",
      "Epoch [7/10] | 训练Acc: 0.9060 | 验证Acc: 0.8906\n",
      "  -> 保存最佳模型\n",
      "Epoch [8/10] | 训练Acc: 0.9324 | 验证Acc: 0.9109\n",
      "  -> 保存最佳模型\n",
      "Epoch [9/10] | 训练Acc: 0.9585 | 验证Acc: 0.9228\n",
      "  -> 保存最佳模型\n",
      "Epoch [10/10] | 训练Acc: 0.9771 | 验证Acc: 0.9334\n",
      "--------------------------------------------------\n",
      "最佳验证集准确率: 0.9334\n",
      "耗时: 93.5秒\n"
     ]
    }
   ],
   "source": [
    "# 模型4: Airbench94 训练\n",
    "import importlib\n",
    "import models.Airbench\n",
    "importlib.reload(models.Airbench)\n",
    "from models.Airbench import CifarNet\n",
    "from models.Muon import Muon\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# CIFAR-10 归一化\n",
    "CIFAR_MEAN = torch.tensor((0.4914, 0.4822, 0.4465), device=device).view(1, 3, 1, 1).half()\n",
    "CIFAR_STD = torch.tensor((0.2470, 0.2435, 0.2616), device=device).view(1, 3, 1, 1).half()\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - CIFAR_MEAN) / CIFAR_STD\n",
    "\n",
    "def batch_flip_lr(inputs):\n",
    "    \"\"\"随机左右翻转\"\"\"\n",
    "    flip_mask = (torch.rand(len(inputs), device=inputs.device) < 0.5).view(-1, 1, 1, 1)\n",
    "    return torch.where(flip_mask, inputs.flip(-1), inputs)\n",
    "\n",
    "def batch_crop(images, crop_size=32, pad=2):\n",
    "    \"\"\"随机裁剪\"\"\"\n",
    "    padded = F.pad(images, (pad, pad, pad, pad), mode='reflect')\n",
    "    b, c, h, w = padded.shape\n",
    "    # 随机偏移\n",
    "    offset_y = torch.randint(0, 2*pad+1, (b,), device=images.device)\n",
    "    offset_x = torch.randint(0, 2*pad+1, (b,), device=images.device)\n",
    "    # 裁剪\n",
    "    cropped = torch.zeros_like(images)\n",
    "    for i in range(b):\n",
    "        cropped[i] = padded[i, :, offset_y[i]:offset_y[i]+crop_size, offset_x[i]:offset_x[i]+crop_size]\n",
    "    return cropped\n",
    "\n",
    "def infer_tta(model, images):\n",
    "    \"\"\"测试时增强 (TTA)\"\"\"\n",
    "    logits = model(images)\n",
    "    logits_flip = model(images.flip(-1))\n",
    "    return 0.5 * logits + 0.5 * logits_flip\n",
    "\n",
    "# 数据准备 - 半精度 + channels_last\n",
    "X_train_air = x_train_pytorch.view(-1, 3, 32, 32).half().to(device).to(memory_format=torch.channels_last)\n",
    "X_val_air = x_val_pytorch.view(-1, 3, 32, 32).half().to(device).to(memory_format=torch.channels_last)\n",
    "y_train_air = y_train_pytorch.to(device)\n",
    "y_val_air = y_val_pytorch.to(device)\n",
    "\n",
    "batch_size = 1000\n",
    "train_dataset = TensorDataset(X_train_air, y_train_air)\n",
    "val_dataset = TensorDataset(X_val_air, y_val_air)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 初始化模型\n",
    "model_air = CifarNet().to(device).to(memory_format=torch.channels_last)\n",
    "model_air.reset()\n",
    "train_images_norm = normalize(X_train_air[:5000])\n",
    "model_air.init_whiten(train_images_norm)\n",
    "\n",
    "# 双优化器配置\n",
    "bias_lr = 0.053\n",
    "head_lr = 0.67\n",
    "wd = 2e-6 * batch_size\n",
    "\n",
    "filter_params = [p for p in model_air.parameters() if len(p.shape) == 4 and p.requires_grad]\n",
    "norm_biases = [p for n, p in model_air.named_parameters() if \"norm\" in n and p.requires_grad]\n",
    "\n",
    "optimizer1 = torch.optim.SGD([\n",
    "    dict(params=[model_air.whiten.bias], lr=bias_lr, weight_decay=wd/bias_lr),\n",
    "    dict(params=norm_biases, lr=bias_lr, weight_decay=wd/bias_lr),\n",
    "    dict(params=[model_air.head.weight], lr=head_lr, weight_decay=wd/head_lr),\n",
    "], momentum=0.85, nesterov=True)\n",
    "\n",
    "optimizer2 = Muon(filter_params, lr=0.24, momentum=0.6, nesterov=True)\n",
    "\n",
    "epochs = 10\n",
    "total_steps = epochs * len(train_loader)\n",
    "whiten_bias_steps = 3 * len(train_loader)\n",
    "\n",
    "best_acc = 0.0\n",
    "step = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"模型4: CifarNet94 准备就绪\")\n",
    "print(f\"开始训练 (共 {epochs} 轮)...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_air.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # 数据增强：归一化 + 随机翻转 + 随机裁剪\n",
    "        images = normalize(images)\n",
    "        images = batch_flip_lr(images)\n",
    "        images = batch_crop(images, crop_size=32, pad=2)\n",
    "\n",
    "        # 学习率调度\n",
    "        for group in optimizer1.param_groups[:1]:\n",
    "            group[\"lr\"] = bias_lr * max(0, 1 - step / whiten_bias_steps)\n",
    "        for group in optimizer1.param_groups[1:]:\n",
    "            group[\"lr\"] = group.get(\"initial_lr\", bias_lr) * (1 - step / total_steps)\n",
    "        for group in optimizer2.param_groups:\n",
    "            group[\"lr\"] = 0.24 * (1 - step / total_steps)\n",
    "\n",
    "        outputs = model_air(images, whiten_bias_grad=(step < whiten_bias_steps))\n",
    "        loss = F.cross_entropy(outputs, labels, label_smoothing=0.2, reduction=\"sum\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        model_air.zero_grad(set_to_none=True)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        step += 1\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # 验证\n",
    "    model_air.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = normalize(images)\n",
    "            outputs = infer_tta(model_air, images)  # TTA\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model_air.state_dict(), 'checkpoints/best_airbench_cifar10.pth')\n",
    "        print(f\"  -> 保存最佳模型\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | 训练Acc: {train_acc:.4f} | 验证Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"最佳验证集准确率: {best_acc:.4f}\")\n",
    "print(f\"耗时: {time.time() - start_time:.1f}秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T06:13:14.530315Z",
     "start_time": "2026-01-09T05:58:14.935285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CifarNet96 参数量: 9,918,776\n",
      "开始训练 (共 50 轮, batch=1024)...\n",
      "------------------------------------------------------------\n",
      "Epoch [5/50] | 训练Acc: 0.2422 | 验证Acc(TTA): 0.2654\n",
      "Epoch [10/50] | 训练Acc: 0.4650 | 验证Acc(TTA): 0.4716\n",
      "Epoch [15/50] | 训练Acc: 0.6710 | 验证Acc(TTA): 0.7304\n",
      "Epoch [20/50] | 训练Acc: 0.7305 | 验证Acc(TTA): 0.7950\n",
      "Epoch [25/50] | 训练Acc: 0.7790 | 验证Acc(TTA): 0.8160\n",
      "Epoch [30/50] | 训练Acc: 0.8193 | 验证Acc(TTA): 0.8318\n",
      "Epoch [35/50] | 训练Acc: 0.8456 | 验证Acc(TTA): 0.8856\n",
      "Epoch [40/50] | 训练Acc: 0.8771 | 验证Acc(TTA): 0.9128\n",
      "Epoch [45/50] | 训练Acc: 0.9116 | 验证Acc(TTA): 0.9282\n",
      "Epoch [50/50] | 训练Acc: 0.9467 | 验证Acc(TTA): 0.9408\n",
      "------------------------------------------------------------\n",
      "最佳验证集准确率: 0.9408\n",
      "耗时: 898.1秒\n"
     ]
    }
   ],
   "source": [
    "# 模型5: CifarNet96\n",
    "import importlib\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import models.Airbench96\n",
    "importlib.reload(models.Airbench96)\n",
    "from models.Airbench96 import CifarNet96, batch_flip_lr, batch_crop, batch_cutout, infer_tta\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "CIFAR_MEAN = torch.tensor((0.4914, 0.4822, 0.4465), device=device).view(1, 3, 1, 1).half()\n",
    "CIFAR_STD = torch.tensor((0.2470, 0.2435, 0.2616), device=device).view(1, 3, 1, 1).half()\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - CIFAR_MEAN) / CIFAR_STD\n",
    "\n",
    "# 数据准备\n",
    "X_train_96 = x_train_pytorch.view(-1, 3, 32, 32).half().to(device).to(memory_format=torch.channels_last)\n",
    "X_val_96 = x_val_pytorch.view(-1, 3, 32, 32).half().to(device).to(memory_format=torch.channels_last)\n",
    "y_train_96 = y_train_pytorch.to(device)\n",
    "y_val_96 = y_val_pytorch.to(device)\n",
    "\n",
    "\n",
    "batch_size = 1024\n",
    "batch_size_masked = 512  # 只训练loss最高的512个\n",
    "train_dataset = TensorDataset(X_train_96, y_train_96)\n",
    "val_dataset = TensorDataset(X_val_96, y_val_96)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 模型初始化\n",
    "model_96 = CifarNet96().to(device).to(memory_format=torch.channels_last)\n",
    "model_96.reset()\n",
    "train_images_norm = normalize(X_train_96[:5000])\n",
    "model_96.init_whiten(train_images_norm)\n",
    "\n",
    "print(f\"CifarNet96 参数量: {sum(p.numel() for p in model_96.parameters()):,}\")\n",
    "\n",
    "# 原版超参数\n",
    "epochs = 45\n",
    "momentum = 0.85\n",
    "kilostep_scale = 1024 * (1 + 1 / (1 - momentum))\n",
    "lr = 9.0 / kilostep_scale\n",
    "wd = 0.012 * batch_size / kilostep_scale\n",
    "lr_biases = lr * 64.0\n",
    "whiten_bias_epochs = 3\n",
    "\n",
    "# 分组参数\n",
    "norm_biases = [p for n, p in model_96.named_parameters() if 'norm' in n and p.requires_grad]\n",
    "other_params = [p for n, p in model_96.named_parameters() if 'norm' not in n and p.requires_grad]\n",
    "param_configs = [\n",
    "    dict(params=norm_biases, lr=lr_biases, weight_decay=wd/lr_biases),\n",
    "    dict(params=other_params, lr=lr, weight_decay=wd/lr)\n",
    "]\n",
    "optimizer = torch.optim.SGD(param_configs, momentum=momentum, nesterov=True)\n",
    "\n",
    "# 学习率调度\n",
    "steps_per_epoch = len(train_loader)\n",
    "total_train_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(total_train_steps * 0.1)\n",
    "\n",
    "def get_lr_mult(step):\n",
    "    if step < warmup_steps:\n",
    "        return 0.2 + 0.8 * (step / warmup_steps)\n",
    "    else:\n",
    "        return (total_train_steps - step) / (total_train_steps - warmup_steps)\n",
    "\n",
    "# Lookahead EMA\n",
    "class LookaheadState:\n",
    "    def __init__(self, net):\n",
    "        self.net_ema = {k: v.clone() for k, v in net.state_dict().items()}\n",
    "    def update(self, net, decay):\n",
    "        for ema_param, net_param in zip(self.net_ema.values(), net.state_dict().values()):\n",
    "            if net_param.dtype in (torch.half, torch.float):\n",
    "                ema_param.lerp_(net_param, 1-decay)\n",
    "                net_param.copy_(ema_param)\n",
    "\n",
    "alpha_schedule = 0.95**5 * (torch.arange(total_train_steps+1) / total_train_steps)**3\n",
    "lookahead = LookaheadState(model_96)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.2, reduction='none')\n",
    "best_acc = 0.0\n",
    "step = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# 预pad数据用于crop\n",
    "pad = 4\n",
    "\n",
    "X_train_padded = F.pad(normalize(X_train_96), (pad,)*4, 'reflect')\n",
    "\n",
    "print(f\"开始训练 (共 {epochs} 轮, batch={batch_size})...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_96.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    # 每epoch随机打乱\n",
    "    perm = torch.randperm(len(X_train_96), device=device)\n",
    "\n",
    "    for i in range(0, len(X_train_96), batch_size):\n",
    "        if i + batch_size > len(X_train_96):\n",
    "            break\n",
    "\n",
    "        indices = perm[i:i+batch_size]\n",
    "        images = X_train_padded[indices]\n",
    "        labels = y_train_96[indices]\n",
    "\n",
    "        # 数据增强: crop from padded\n",
    "        r = pad\n",
    "        shifts = torch.randint(-r, r+1, size=(len(images), 2), device=device)\n",
    "        images_cropped = torch.empty((len(images), 3, 32, 32), device=device, dtype=images.dtype)\n",
    "        for sy in range(-r, r+1):\n",
    "            for sx in range(-r, r+1):\n",
    "                mask = (shifts[:, 0] == sy) & (shifts[:, 1] == sx)\n",
    "                if mask.any():\n",
    "                    images_cropped[mask] = images[mask, :, r+sy:r+sy+32, r+sx:r+sx+32]\n",
    "\n",
    "        # 交替翻转 (alternating flip)\n",
    "        if epoch % 2 == 1:\n",
    "            images_cropped = images_cropped.flip(-1)\n",
    "\n",
    "        # Cutout\n",
    "        images_cropped = batch_cutout(images_cropped, size=12)\n",
    "\n",
    "        # 学习率调度\n",
    "        lr_mult = get_lr_mult(step)\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = g['initial_lr'] * lr_mult if 'initial_lr' in g else lr_biases * lr_mult\n",
    "        optimizer.param_groups[0]['lr'] = lr_biases * lr_mult\n",
    "        optimizer.param_groups[1]['lr'] = lr * lr_mult\n",
    "\n",
    "        # 前向传播\n",
    "        whiten_bias_grad = (epoch < whiten_bias_epochs)\n",
    "        outputs = model_96(images_cropped, whiten_bias_grad=whiten_bias_grad)\n",
    "        loss_all = loss_fn(outputs, labels)\n",
    "\n",
    "        # Hard Sample Mining: 只训练loss最高的batch_size_masked个\n",
    "        mask = torch.zeros(len(images_cropped), device=device, dtype=torch.bool)\n",
    "        mask[loss_all.argsort()[-batch_size_masked:]] = True\n",
    "        loss = loss_all[mask].sum()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Lookahead更新\n",
    "        step += 1\n",
    "        if step % 5 == 0:\n",
    "            lookahead.update(model_96, decay=alpha_schedule[step].item())\n",
    "\n",
    "        _, predicted = torch.max(outputs[mask].data, 1)\n",
    "        train_total += mask.sum().item()\n",
    "        train_correct += (predicted == labels[mask]).sum().item()\n",
    "\n",
    "    # 最后一步Lookahead\n",
    "    if epoch == epochs - 1:\n",
    "        lookahead.update(model_96, decay=1.0)\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # 验证\n",
    "    model_96.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = normalize(images)\n",
    "            outputs = infer_tta(model_96, images, tta_level=2)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model_96.state_dict(), 'checkpoints/best_airbench96_cifar10.pth')\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | 训练Acc: {train_acc:.4f} | 验证Acc(TTA): {val_acc:.4f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"最佳验证集准确率: {best_acc:.4f}\")\n",
    "print(f\"耗时: {time.time() - start_time:.1f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、模型测试\n",
    "+ 使用上面的模型在分别在测试集上测试，输出准确率，找到最优模型。\n",
    "+ 将最优模型保存为文件，方便后续的模型部署。\n",
    "    sklearn 参考： https://scikit-learn.org/stable/model_persistence.html\n",
    "    pytroch 参考： https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "+ 输出最优模型的准确率，作为评分依据之一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T12:58:59.303402Z",
     "start_time": "2026-01-08T12:58:58.698664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost模型已加载\n",
      "\n",
      "============================================================\n",
      "模型测试结果\n",
      "============================================================\n",
      "模型1 XGBoost 测试集准确率: 0.5371\n"
     ]
    }
   ],
   "source": [
    "with open(\"checkpoints/best_xgboost_cifar10.pkl\", \"rb\") as f:\n",
    "    best_model_xgb = pickle.load(f)\n",
    "print(\"XGBoost模型已加载\")\n",
    "\n",
    "# ==================== 模型测试 ====================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"模型测试结果\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_pred_xgb = best_model_xgb.predict(x_test_sklearn)\n",
    "acc_xgb = accuracy_score(y_test, test_pred_xgb)\n",
    "print(f\"模型1 XGBoost 测试集准确率: {acc_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T13:11:19.497996Z",
     "start_time": "2026-01-08T13:11:18.798580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN模型已加载\n",
      "模型2 CNN 测试集准确率: 0.7802\n"
     ]
    }
   ],
   "source": [
    "from models.CNN import CIFAR10_CNN\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model_cnn = CIFAR10_CNN().to(device)\n",
    "best_model_cnn.load_state_dict(torch.load(\"checkpoints/best_cnn_cifar10.pth\",weights_only=True))\n",
    "print(\"CNN模型已加载\")\n",
    "\n",
    "X_test_cnn = torch.from_numpy(x_test).float().view(-1, 3, 32, 32).to(device)\n",
    "y_test_tensor = torch.from_numpy(y_test).long().to(device)\n",
    "\n",
    "best_model_cnn.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = best_model_cnn(X_test_cnn)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    acc_cnn = (predicted == y_test_tensor).sum().item() / len(y_test)\n",
    "\n",
    "print(f\"模型2 CNN 测试集准确率: {acc_cnn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T13:12:24.432731Z",
     "start_time": "2026-01-08T13:11:51.379957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-18模型已加载\n",
      "模型3 ResNet-18 测试集准确率: 0.8185\n"
     ]
    }
   ],
   "source": [
    "from models.ResNet import ResNet18\n",
    "\n",
    "best_model_res = ResNet18().to(device)\n",
    "best_model_res.load_state_dict(torch.load(\"checkpoints/best_resnet18_cifar10.pth\", weights_only=True))\n",
    "print(\"ResNet-18模型已加载\")\n",
    "\n",
    "best_model_res.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = best_model_res(X_test_cnn)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    acc_res = (predicted == y_test_tensor).sum().item() / len(y_test)\n",
    "print(f\"模型3 ResNet-18 测试集准确率: {acc_res:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T06:17:35.139732Z",
     "start_time": "2026-01-09T06:17:34.516008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CifarNet 参数量: 1,972,792\n",
      "CifarNet 测试集准确率: 0.9243\n"
     ]
    }
   ],
   "source": [
    "# 读取评测 CifarNet 模型 (93%版本)\n",
    "import importlib\n",
    "import models.Airbench\n",
    "importlib.reload(models.Airbench)\n",
    "from models.Airbench import CifarNet\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "CIFAR_MEAN = torch.tensor((0.4914, 0.4822, 0.4465), device=device).view(1, 3, 1, 1).half()\n",
    "CIFAR_STD = torch.tensor((0.2470, 0.2435, 0.2616), device=device).view(1, 3, 1, 1).half()\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - CIFAR_MEAN) / CIFAR_STD\n",
    "\n",
    "# 加载模型\n",
    "model_air = CifarNet().to(device).to(memory_format=torch.channels_last)\n",
    "model_air.load_state_dict(torch.load('checkpoints/best_airbench_cifar10.pth', weights_only=True))\n",
    "model_air.eval()\n",
    "\n",
    "print(f\"CifarNet 参数量: {sum(p.numel() for p in model_air.parameters()):,}\")\n",
    "\n",
    "# 准备测试数据\n",
    "X_test = x_test_pytorch.view(-1, 3, 32, 32).half().to(device).to(memory_format=torch.channels_last)\n",
    "y_test = y_test_pytorch.to(device)\n",
    "\n",
    "# 评估\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_test), 500):\n",
    "        images = normalize(X_test[i:i+500])\n",
    "        labels = y_test[i:i+500]\n",
    "        outputs = model_air(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"CifarNet 测试集准确率: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T06:15:48.253255Z",
     "start_time": "2026-01-09T06:15:44.682634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CifarNet96 参数量: 9,918,776\n",
      "CifarNet96 测试集准确率 (TTA): 0.9558\n"
     ]
    }
   ],
   "source": [
    "# 读取评测 CifarNet96 模型\n",
    "import importlib\n",
    "import models.Airbench96\n",
    "importlib.reload(models.Airbench96)\n",
    "from models.Airbench96 import CifarNet96, infer_tta\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "CIFAR_MEAN = torch.tensor((0.4914, 0.4822, 0.4465), device=device).view(1, 3, 1, 1).half()\n",
    "CIFAR_STD = torch.tensor((0.2470, 0.2435, 0.2616), device=device).view(1, 3, 1, 1).half()\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - CIFAR_MEAN) / CIFAR_STD\n",
    "\n",
    "# 加载模型\n",
    "model_96 = CifarNet96().to(device).to(memory_format=torch.channels_last)\n",
    "model_96.load_state_dict(torch.load('checkpoints/best_airbench96_cifar10.pth', weights_only=True))\n",
    "model_96.eval()\n",
    "\n",
    "print(f\"CifarNet96 参数量: {sum(p.numel() for p in model_96.parameters()):,}\")\n",
    "\n",
    "# 准备测试数据\n",
    "X_test = x_test_pytorch.view(-1, 3, 32, 32).half().to(device).to(memory_format=torch.channels_last)\n",
    "y_test = y_test_pytorch.to(device)\n",
    "\n",
    "# 评估 (带TTA)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_test), 500):\n",
    "        images = normalize(X_test[i:i+500])\n",
    "        labels = y_test[i:i+500]\n",
    "        outputs = infer_tta(model_96, images, tta_level=2)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"CifarNet96 测试集准确率 (TTA): {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVA模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:33:39.383268Z",
     "start_time": "2026-01-09T12:32:06.421815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== shape of rope freq torch.Size([256, 64]) ========\n",
      "EVA-02 参数量: 85,766,410\n",
      "EVA-02 测试集准确率: 0.9879\n"
     ]
    }
   ],
   "source": [
    "# 读取评测 EVA-02 模型\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from EVA import modeling_finetune\n",
    "from timm.models import create_model\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# EVA 配置\n",
    "MODEL_NAME = 'eva02_base_patch14_xattn_fusedLN_NaiveSwiGLU_subln_RoPE'\n",
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
    "STD = (0.26862954, 0.26130258, 0.27577711)\n",
    "\n",
    "# 图像预处理 (32->224)\n",
    "transform_eva = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=3),\n",
    "    transforms.CenterCrop(INPUT_SIZE),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "# 加载模型\n",
    "model_eva = create_model(MODEL_NAME, pretrained=False, num_classes=NUM_CLASSES,\n",
    "                         drop_rate=0.0, drop_path_rate=0.0, attn_drop_rate=0.0, use_mean_pooling=True)\n",
    "checkpoint = torch.load('checkpoints/best_eva_cifar10.pth', map_location='cpu', weights_only=False)\n",
    "state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint\n",
    "model_eva.load_state_dict(state_dict, strict=False)\n",
    "model_eva = model_eva.to(device).eval()\n",
    "\n",
    "print(f\"EVA-02 参数量: {sum(p.numel() for p in model_eva.parameters()):,}\")\n",
    "\n",
    "# 准备测试数据\n",
    "X_test_eva = x_test_pytorch.view(-1, 3, 32, 32).float().to(device)\n",
    "\n",
    "# 评估\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_test_eva), 32):\n",
    "        images = X_test_eva[i:i+32]\n",
    "        labels = y_test_pytorch[i:i+32].to(device)\n",
    "        # Resize + Normalize\n",
    "        images = F.interpolate(images, size=224, mode='bilinear', align_corners=False)\n",
    "        images = (images - torch.tensor(MEAN, device=device).view(1,3,1,1)) / torch.tensor(STD, device=device).view(1,3,1,1)\n",
    "        outputs = model_eva(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"EVA-02 测试集准确率: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、模型部署\n",
    "自行学习streamlit的使用以及编程方法\n",
    "\n",
    "使用上面训练得到的模型，采用[streamlit](https://streamlit.io/)构建一个web demo, 上传图像，输出图像对应的分类名称。\n",
    "参考：\n",
    "+ [Streamlit documentation](https://docs.streamlit.io/)\n",
    "+ https://stevensmiley1989.medium.com/train-deploy-yolov7-to-streamlit-5a3e925690a9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
